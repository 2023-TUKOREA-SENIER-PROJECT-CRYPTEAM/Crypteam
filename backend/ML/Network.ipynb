{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, Conv1D, \\\n",
    "    BatchNormalization, Dropout, MaxPooling1D, Flatten\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from Indicator import *\n",
    "from DataScaler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self,input_dim = 0, output_dim = 0, lr = 0.001,\n",
    "                activation = \"relu\", loss = \"BC\"):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lr = lr\n",
    "        self.activation = activation\n",
    "        if loss == \"mse\":\n",
    "            self.loss = tf.keras.losses.MeanSquaredError()\n",
    "        elif loss == \"BC\":\n",
    "            self.loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    \n",
    "    def predict(self,x):\n",
    "        pass\n",
    "\n",
    "class DNN(Network):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model = self.get_network_head()\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.lr),\n",
    "                           metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    "                            loss = self.loss)\n",
    "\n",
    "    def get_network_head(self):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Dense(256,input_shape = (self.input_dim,)))\n",
    "        model.add(keras.layers.Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(128,activation=self.activation))\n",
    "        model.add(keras.layers.Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(64,activation=self.activation))\n",
    "        model.add(keras.layers.Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(32,activation=self.activation))\n",
    "        model.add(keras.layers.Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n",
    "        return model\n",
    "\n",
    "    def train_on_batch(self, x, y):\n",
    "        self.model.fit(x,y,batch_size = 1024, epochs = 5)\n",
    "\n",
    "    def predict(self, sample):\n",
    "        sample = np.array(sample).reshape((-1, self.input_dim))\n",
    "        return self.model.predict(sample)\n",
    "    \n",
    "class LSTMNetwork(Network):\n",
    "    def __init__(self, num_steps, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.num_steps = num_steps\n",
    "        self.model = self.get_network_head()\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=self.lr),\n",
    "                           metrics=[tf.keras.metrics.BinaryAccuracy()],\n",
    "                            loss=self.loss)\n",
    "    def make_dataset(self,data, label, window_size=20):\n",
    "        feature_list = []\n",
    "        label_list = []\n",
    "        print(\">>LSTM Data transpose\")\n",
    "        for i in tqdm(range(len(data) - window_size)):\n",
    "            feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
    "            label_list.append(np.array(label.iloc[i+window_size - 1]))\n",
    "        return np.array(feature_list), np.array(label_list)\n",
    "    def get_network_head(self):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(LSTM(256, input_shape = (self.num_steps,self.input_dim)))\n",
    "        model.add(keras.layers.Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(128,activation=self.activation))\n",
    "        model.add(keras.layers.Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(64,activation=self.activation))\n",
    "        model.add(keras.layers.Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(32,activation=self.activation))\n",
    "        model.add(keras.layers.Dropout(0.1))\n",
    "        model.add(keras.layers.Dense(1,activation=\"sigmoid\"))\n",
    "        return model\n",
    "\n",
    "    def train_on_batch(self, x, y):\n",
    "        x,y = self.make_dataset(x,y)\n",
    "        self.model.fit(x, y, batch_size = 1024, epochs = 1)\n",
    "\n",
    "    def predict(self, x):\n",
    "        pred = self.model.predict(x)\n",
    "        return pred\n",
    "class LogisticNetwork(Network):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model = self.get_network_head()\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "    def get_network_head(self):\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(keras.layers.Dense(256,input_shape = (self.input_dim,)))\n",
    "        model.add(keras.layers.Dense(1))\n",
    "        return model\n",
    "\n",
    "    def train_on_batch(self,x,y):\n",
    "        self.model.fit(x,y,batch_size = 256, epochs = 10)\n",
    "        \n",
    "class Xgboost(Network):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.model = self.get_network_head()\n",
    "\n",
    "    def get_network_head(self):\n",
    "        return XGBClassifier(max_depth = 10)\n",
    "    \n",
    "    def train_on_batch(self,x,y):\n",
    "        self.model.fit(x, y)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"labeled_data.csv\").drop([\"Unnamed: 0\"],axis=1)\n",
    "parameter = [\n",
    "        {\"rsi\" : {\"period\" : 14}},\n",
    "        {\"ma\" : {\"period\" : 7}},\n",
    "        {\"ma\" : {\"period\" : 25}},\n",
    "        {\"ema\" :{\"period\" : 7}},\n",
    "        {\"ema\" :{\"period\" : 25}},\n",
    "        {\"stochastic\" : {\"n\" : 14,\"m\" : 5,\"t\" : 5}},\n",
    "        {\"bb\" : {\"length\" : 21,\"std\" : 2}},\n",
    "        {\"kdj\" : {}},\n",
    "        {\"macd\" : {\"fast_period\": 12, \"slow_period\" : 26}}\n",
    "]\n",
    "DataManageBot = DataManage(data, parameter = parameter)\n",
    "data = DataManageBot.get_data()\n",
    "data.head()\n",
    "x = data.drop(['datetime','label'],axis=1)\n",
    "y = data.label\n",
    "# x,y = make_dataset(x,y)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size = int(len(df) * 0.2)\n",
    "test_size = 1440 * 30\n",
    "X,Y = data.drop(['label','datetime'],axis = 1),data['label']\n",
    "X = Data_StandardScaler(X)\n",
    "\n",
    "x_train = X[:-test_size]\n",
    "y_train = Y[:-test_size]\n",
    "x_test = X[-test_size:]\n",
    "y_test = Y[-test_size:]\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ensembleModel:\n",
    "    def __init__(self,num_step, input_dim):\n",
    "        self.DNNModel = DNN(input_dim = input_dim)\n",
    "        self.LSTMModel = LSTMNetwork(input_dim = input_dim, num_steps = num_step)\n",
    "        self.LRModel = LogisticNetwork(input_dim = input_dim)\n",
    "        self.XGBoostModel = Xgboost(input_dim = input_dim)\n",
    "        self.DNNPredict = None\n",
    "        self.LRPredict = None\n",
    "        self.XGBoostPredict = None\n",
    "        self.LSTMPredict = None\n",
    "    def models_fit(self,x,y):\n",
    "        print(\">> DNN Training...\")\n",
    "        self.DNNModel.train_on_batch(x,y)\n",
    "        print(\">> Logistic Training...\")\n",
    "        self.LRModel.train_on_batch(x,y)\n",
    "        print(\">> XGBoost Training...\")\n",
    "        self.XGBoostModel.train_on_batch(x,y)\n",
    "        print(\">> LSTM Training...\")\n",
    "        self.LSTMModel.train_on_batch(x,y)\n",
    "    #  0 <= threshold < 0.5\n",
    "    def predict_and_evaluation(self,x, threshold = 0):\n",
    "        self.DNNPredict = self.DNNModel.predict(x_test)\n",
    "        self.LRPredict = self.LRModel.model.predict(x_test)\n",
    "        self.XGBoostPredict = self.XGBoostModel.model.predict(x_test)\n",
    "        LSTM_x_test, LSTM_y_test = self.LSTMModel.make_dataset(x_test,y_test)\n",
    "        self.LSTMPredict = self.LSTMModel.predict(LSTM_x_test)\n",
    "\n",
    "        DNNPredict = self.DNNPredict.reshape(-1,)\n",
    "        LRPredict = self.LRPredict.reshape(-1,)\n",
    "        XGBoostPredict = self.XGBoostPredict.reshape(-1,)\n",
    "        LSTMPredict = self.LSTMPredict.reshape(-1,)\n",
    "        result_label = []\n",
    "        cnt = 0\n",
    "        for i in range(len(DNNPredict)):\n",
    "            if DNNPredict[i] > 0.8 and LRPredict[i] > 0.8 and XGBoostPredict[i] > 0.8 and LSTMPredict[i] > 0.8:\n",
    "                result_label.append(1)\n",
    "            elif DNNPredict[i] < 0.2 and LRPredict[i] < 0.2 and XGBoostPredict[i] < 0.2 and LSTMPredict[i] < 0.2:\n",
    "                result_label.append(0)\n",
    "            else:\n",
    "                result_label.append(-1)\n",
    "                cnt += 1\n",
    "\n",
    "        ck = 0 # 정답 카운트\n",
    "        cnt = 0 # 총 카운트\n",
    "        for i in range(len(result_label)):\n",
    "            if result_label[i] != -1:\n",
    "                if result_label[i] == y_test.iloc[i]:\n",
    "                    ck += 1\n",
    "                cnt += 1\n",
    "        print(\"accuracy :\",round(ck/cnt * 100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = ensembleModel(20, x_train.shape[1])\n",
    "ensemble.models_fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNNPredict = ensemble.DNNModel.predict(x_test)\n",
    "LRPredict = ensemble.LRModel.model.predict(x_test)\n",
    "XGBoostPredict = ensemble.XGBoostModel.model.predict(x_test)\n",
    "LSTM_x_test, LSTM_y_test = ensemble.LSTMModel.make_dataset(x_test,y_test)\n",
    "LSTMPredict = ensemble.LSTMModel.predict(LSTM_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNNPredict = DNNPredict.reshape(-1,)\n",
    "LRPredict = LRPredict.reshape(-1,)\n",
    "XGBoostPredict = XGBoostPredict.reshape(-1,)\n",
    "LSTMPredict = list([-1 for i in range(20)]) + list(LSTMPredict.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_label = []\n",
    "cnt = 0\n",
    "for i in range(len(DNNPredict)):\n",
    "    if DNNPredict[i] > 0.85:\n",
    "        result_label.append(1)\n",
    "    elif DNNPredict[i] <0.15:\n",
    "        result_label.append(0)\n",
    "    else:\n",
    "        result_label.append(-1)\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_label = []\n",
    "cnt = 0\n",
    "for i in range(len(DNNPredict)):\n",
    "    if LSTMPredict[i] > 0.9 and DNNPredict[i] > 0.9 and LRPredict[i] > 0.9 and XGBoostPredict[i] == 1:\n",
    "        result_label.append(1)\n",
    "    elif LSTMPredict[i] < 0.1 and DNNPredict[i] < 0.1 and LRPredict[i] < 0.1 and XGBoostPredict[i] == 0:\n",
    "        result_label.append(0)\n",
    "    else:\n",
    "        result_label.append(-1)\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck = 0 # 정답 카운트\n",
    "cnt = 0 # 총 카운트\n",
    "report_list = []\n",
    "report_pred = []\n",
    "for i in range(len(result_label)):\n",
    "    if result_label[i] != -1:\n",
    "        if result_label[i] == y_test.iloc[i]:\n",
    "            ck += 1\n",
    "        cnt += 1\n",
    "print(\"accuracy :\",round(ck/cnt * 100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = data.iloc[-test_size:].drop([\"datetime\", \"label\"],axis = 1)\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def checking_labeling(labeling_data):\n",
    "    step = 1000\n",
    "    for i in range(0, len(labeling_data), step):\n",
    "        name = str(labeling_data.iloc[i][\"datetime\"])+ \" ~ \" + str(labeling_data.iloc[i + step - 1][\"datetime\"])\n",
    "        fig = plt.figure(figsize=(16,9))\n",
    "        fig = plt.title(name)\n",
    "        fig = plt.plot(labeling_data.iloc[i:i + step][\"datetime\"], labeling_data.iloc[i:i + step][\"close\"])\n",
    "        for j in range(i, i + step):\n",
    "            if labeling_data.iloc[j][\"result_label\"] == 0:\n",
    "                fig = plt.scatter(labeling_data.iloc[j][\"datetime\"], labeling_data.iloc[j][\"close\"], color = \"r\")\n",
    "            if labeling_data.iloc[j][\"result_label\"] == 1:\n",
    "                fig = plt.scatter(labeling_data.iloc[j][\"datetime\"], labeling_data.iloc[j][\"close\"], color = \"b\")\n",
    "        \n",
    "        plt.savefig(\"ML_Result/\" + name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = pd.concat([data.iloc[-test_size:].reset_index(), pd.DataFrame(result_label,columns=[\"result_label\"])],axis=1)\n",
    "result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_labeling(result_data[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Network import ensembleModel\n",
    "model = ensembleModel(20,x_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.models_fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
